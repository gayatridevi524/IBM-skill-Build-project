# -*- coding: utf-8 -*-
"""Employee Burnout prediction and Analysis .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17QYb5viay2NkYzSrpTPh0lREDFCJngau

**Importing Libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

import warnings
warnings.filterwarnings('ignore') #ignoring warning messages during code execution

# Loading files from the colab
from google.colab import files
uploaded = files.upload()

"""**Loading Dataset**"""

#reads the csv file
data = pd.read_csv("employee_burnout.csv")
data  #prints the loaded dataset

#returns the shape of the dataset
data.shape

#returns the structure and type of data stored
data.info()

# converting string to datetime data type
data["Date of Joining"]=pd.to_datetime(data["Date of Joining"])

# now the data type of the DOJ column changed to datetime
data.info()

#returns the first 5 rows of the data
data.head()

# returns the columns present in the data
data.columns

# calculates the number of null values in each column of the data
data.isna().sum()

# checks for the duplicated values
data.duplicated().sum()

# calculates the mean,std,min,max,count of every attribute
data.describe()

# shows the unique values
for col in data.columns:
    unique_values = data[col].unique()#retrives unique values in the current column of data
    value_counts = data[col].value_counts()# calculates the count of each unique value in the current column using value_counts function
    print(f"\n\n{unique_values}")
    print(f"\n{value_counts}\n\n")

# Droping out the irrelevant column as it was no longer required
data=data.drop(["Employee ID"],axis=1)

# Replaces null values with mean values
data["Resource Allocation"].fillna(data["Resource Allocation"].mean(),inplace=True)
data["Mental Fatigue Score"].fillna(data["Mental Fatigue Score"].mean(),inplace=True)
data["Burn Rate"].fillna(data["Burn Rate"].mean(),inplace=True)

# again check for the null values
data.isna().sum()

# calculates the correlation between the features of data -1 indicates negative,0 indicates none,+1 indicates positive
data.corr()

"""**Data Visualization**"""

# Plotting heatmap to check the correlation
corr = data.corr()
fig, ax = plt.subplots(figsize=(15, 8))
sns.heatmap(corr, annot=True, fmt=".6f", cmap="magma", ax=ax)
plt.show()

# Count plot distribution based on Gender
plt.figure(figsize=(10, 8))
sns.set_theme(style="darkgrid", palette="dark")
sns.countplot(x="Gender", data=data)
plt.title("Plot distribution for Gender")
plt.show()

#count plot distribution of company type
plt.figure(figsize=(10,8))
sns.countplot(x = 'Company Type', data = data,palette='plasma');
plt.title("plot distribution of Company Type")
plt.show()

#count plot distribution of "WFH setup available"
plt.figure(figsize=(10,8))
sns.countplot(x="WFH Setup Available",data=data,palette="dark:salmon_r")
plt.title("plot distribution of WFH Setup Available")
plt.show()

#count plot distribution of attributes with the help of histogram
burn_st=data.loc[:,"Date of Joining":"Burn Rate"]
burn_st=burn_st.select_dtypes([int,float])
color_sequence = ["steelblue"]
for col in burn_st.columns:
  fig=px.histogram(burn_st,x=col,title="plot distribution of "+col,color_discrete_sequence=color_sequence)
  fig.update_layout(bargap=0.2)
  fig.show()

#plot distribution of the Burn rate on the basis of Designation
fig=px.line(data,y="Burn Rate",color="Designation",title="Burn Rate on the basis of Designation",color_discrete_sequence=px.colors.qualitative.Pastel1)
fig.update_layout(bargap=0.1)
fig.show()

#Plot distribution of burn rate on the basis of Resource Allocation
plt.figure(figsize=(10, 8))
sns.lineplot(data=data, x="Burn Rate", y="Resource Allocation", palette="Pastel1")
plt.title("Burn Rate on the basis of Resource Allocation")
plt.show()

#plot distribution of mental fatigue score on the basis of Designation
plt.figure(figsize=(10, 8))
sns.relplot(data=data, x="Burn Rate", y="Mental Fatigue Score", palette="Pastel1")
plt.title("Burn Rate on the basis of Mental Fatigue Score")
plt.show()

#plot distribution of "Designation vs mental fatigue" as per Company type,Burn rate and Gender
sns.relplot(
    data=data,x="Designation",y="Mental Fatigue Score",col="Company Type",
    hue="Company Type",size="Burn Rate",style="Gender",
    palette=['g','r'],sizes=(50,200)
)

# calculation based on some stats related to burnout rate
data['Burnout Category'] = np.where(
    data['Burn Rate'] > 0.7, "Extreme",
    np.where((data["Burn Rate"] >= 0.5) & (data["Burn Rate"] < 0.7), "Moderate",
    np.where(data['Burn Rate'] < 0.5, "Slight", "No Burnout"  )))

#Plot distribution of Burnout Category based on Gender
fig = px.histogram(data, x="Burnout Category", color="Gender", title="Count of Burnout Category by Gender",
                   color_discrete_sequence=["steelblue", "indianred"])
fig.show()

#Plot distribution of Burnout Category based on Company Type
fig = px.histogram(data, x="Burnout Category", color="Company Type", title="Count of Burnout Category by Company Type",
                   color_discrete_sequence=["steelblue", "purple"])
fig.show()

#plot distribution of burnout category based on Designation
sns.countplot(x = "Burnout Category", data = data, hue = "Designation");
plt.title("plot distribution of burnout category based on Designation")
plt.show()

#plot distribution of burnout category based on Resource Allocation
sns.relplot(x = "Resource Allocation", y = "Burn Rate", data = data, hue = "Burnout Category");
plt.title("plot distribution of burnout category based on Resource Allocation")
plt.show()

"""**Label Encoding**"""

# Importing Label Encoder and assigning it to a new variable
from sklearn import preprocessing
label_encode=preprocessing.LabelEncoder()

data['GenderLabel']=label_encode.fit_transform(data["Gender"].values)
data["Company_TypeLabel"]=label_encode.fit_transform(data["Company Type"].values)
data['WFH_Setup_AvailableLabel']=label_encode.fit_transform(data["WFH Setup Available"].values)

#check assigned values for Gender
gn=data.groupby('Gender')
gn=gn['GenderLabel']
gn.first()

#ckeck assigned values for Company Type
ct=data.groupby('Company Type')
ct=ct["Company_TypeLabel"]
ct.first()

#checks assigned value for WFH setup available
wsa=data.groupby('WFH Setup Available')
wsa=wsa['WFH_Setup_AvailableLabel']
wsa.first()

# returns the last 10 rows of the data
data.tail(10)

"""**Feature Selection**"""

# Feature Selection
columns=['Designation','Resource Allocation','Mental Fatigue Score',
         'GenderLabel','Company_TypeLabel','WFH_Setup_AvailableLabel']
X=data[columns] # independent variables
y=data["Burn Rate"] # dependent variable

print(X)

print(y)

"""**Data Splitting**"""

# splits the dataset into train and test sets
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=10)

# print the shape of the splitting data
print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)

"""**Model Implementation**"""

from sklearn.metrics import r2_score,mean_squared_error

#Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor

# Create and fit the Random Forest regression model
rf_model=RandomForestRegressor()
rf_model.fit(X_train,y_train)

# Make predictions on the train set
train_pred_rf=rf_model.predict(X_train)

# Make predictions on the test set
test_pred_rf=rf_model.predict(X_test)

#Accuracy Score
test_r2=r2_score(y_test,test_pred_rf)
print("Accuracy score of test data: "+str(round(100*test_r2,4))+"%")
#Mean Squared Error
mse = mean_squared_error(y_test, test_pred_rf)
print("Mean Squared Error is: ", mse)

from sklearn.ensemble import GradientBoostingRegressor

# Create and fit the gradient boosting regression model
gb_model = GradientBoostingRegressor()
gb_model.fit(X_train, y_train)

# Make predictions on the training set
train_pred_gb = gb_model.predict(X_train)

# Make predictions on the test set
test_pred_gb = gb_model.predict(X_test)

# Accuracy Score
test_r2 = r2_score(y_test, test_pred_gb)
print("Accuracy score of test data: " + str(round(100 * test_r2, 4)) + "%")
#Mean Squared Error
mse = mean_squared_error(y_test, test_pred_gb)
print("Mean Squared Error is: ", mse)

# testing the model
new_employee = [[4, 8.0, 7.5, 1, 0, 1]]  # Example features for the new employee
predicted_burnout_rate = gb_model.predict(new_employee)
print("Predicted Burnout Rate for the new employee:", predicted_burnout_rate)
if predicted_burnout_rate>=0.7:
  print("the employee falls under Extremely burned out")
elif predicted_burnout_rate>=0.5 and predicted_burnout_rate<0.7:
  print("The employee falls under Moderately burned out")
elif predicted_burnout_rate>0.0 and predicted_burnout_rate<0.5:
  print("The employee falls under Slightly burned out")
else:
  print("The employee not burned out")